Notes for minishell

These notes describe how I want to build the lexer + parser + executor.


Bash reference: 	https://www.gnu.org/software/bash/manual/bash.html#Shell-Expansions
				or	http://www.opengroup.org/onlinepubs/9699919799/utilities/V3_chap01.html
				or	https://www.computerhope.com/unix/ubash.htm


minishell

	1.	First things first: Read user input with read_line() function

		1.x To do:
			-	Read environment variables

	2.	Lexical analysis

		2.1	Tokenize user input

		-	In order to process user input into commands
			minishell splits the the input line into tokens.
			All tokens will be stored inside a linked list of token structs.

			typedef struct	s_token
			{
				int				id;		//	token type		(e.g: WORD)
				char			*str;	//	token string	(e.g: "echo")
				struct s_token	*next;	//	pointer to next token
			}				t_token;

			Shell Manual:
			"A character that, when unquoted, separates words. A metacharacter is a space, tab, newline, 
			or one of the following characters: ‘|’, ‘&’, ‘;’, ‘(’, ‘)’, ‘<’, or ‘>’."

			For the mandatory part these characters are considered as metacharacters:
			
			' '		-	single space	-	word seperator
			'\t'	-	tab space		-	word seperator
			'\n'	-	newline			-	word seperator
			';'		-	semicolon		-	list terminator
			'\''	-	single quote	-	enlosing character
			'\"'	-	double quote	-	enlosing character
			'<'		-	less than		-	redirection operator
			'>'		-	bigger than		-	redirection operator
			'>>'	-	2x bigger than	-	redirection operator
			'|'		-	pipe			-	pipe operator
		
		-	Redirection oparators, pipes and list terminators will also 
			get parsed into seperate tokens. ("<", ">", "|", ";" or ">>")
		
		-	Parsing steps for words and oparator tokens:

			1.	Start iterating through input line with an index variabel i = 0.

			2.	If line[i] is not a metacharacter then copy the character into a token string.
				->	token[j] = line[i]
				->	j++;
				->	i++;

			3.	If line[i] is a space, tab or newline character 
				and there were non metacharacters read into the token string previously
				then stop reading the current token and create a new empty token
				(token strings are allocated with ft_calloc so null termination is not needed)
				->	token->next = ft_calloc(1, sizeof(t_token));
				->	token = token->next;
				->	token->str = ft_calloc(strlen(line) - i, sizeof(char));

			4.	If line[i] matches one of those chars in this string ";<>|"
				then do the same instructions as in step 3.
				Additionally create a new token which contains the operator character itself.
				Then make a new empty token.
				->	token->str[0] = '<'		// example
				->	token->next = ft_calloc(1, sizeof(t_token));
				->	token = token->next;
				->	token->str = ft_calloc(strlen(line) - i, sizeof(char));
			
			5.	If line[i] is a quote character '\"' or '\'' then minishell
				checks first if the quotes have a matching closing quote.
				If so then everything between those quotes gets copied into new token.
				If there is no second quote of the same type present in the input string then
				the behaviour results in a syntax error.

			6.	Basic syntax checks are currently present within the tokenizer.
				Deep syntax checking will happen at a later stage.

				Basic syntax checks include:
					-	multiple semicolons "echo ;;"
					-	open quotes	"echo 'abc "
					-	invalid operators "echo >>>"
					-	and a bit more...
	
		
		-	Each token gets a value assigned as described below.

			#define EMPTY 0
			#define WORD 1
			#define SQUOTE 2
			#define DQUOTE 4
			#define SEMICOLON 8
			#define PIPE 16
			#deinfe REDIR_IN 32
			#deinfe REDIR_OUT 64

		-	Let's consider the following input line:
			// VAR=42
				echo "42 is $VAR" -n | grep "1" < 1.txt

			The tokenizer will create this list of tokens:

			token->str		token->type
			"echo"		|	WORD
			"42 is $VAR"|	DQUOTE
			"-n"		|	WORD
			"|"			|	PIPE
			"grep"		|	WORD
			"1"			|	DQUOTE
			"<"			|	REDIR_IN
			"1.txt"		|	WORD
			""			|	EMPTY


		2.2	Shell Expansions	-	still to do
			
			-	As stated in the bash manual:
				"Expansion is performed on the command line after it has been split into tokens."
			
			-	Order of expansions:
				1.	Tilde expansion - dunno if mandatory
				2.	Parameter and variable expansion
					->	$?, $SHLVL, $ARG, "$ARG"
				3.	Word splitting after expansion
					-> 	Explicit null arguments ("" or '') are retained and
						passed to commands as empty strings.
					-> 	Unquoted implicit null arguments resulting from expansion
						are removed
					-> 	If a parameter with no value is expanded within double quotes,
						a null argument results and passed to command as empty string
					->	When a quoted null argument appears as part of a word whose
						expansion is non-null, the null argument is removed.
					->	the word -d'' becomes -d after word splitting and null argument removal.
				4.	Pathname expansion
		
			-	After these expansions are performed, quote characters present in the original
				word are removed unless they have been quoted themselves

			-	Expansions must be done before building abstract syntax tree

			After expanding the pathnames and variables the token list 
			will look like this:

			// VAR=42
				echo "42 is $VAR" -n | grep "1" < 1.txt		# initial command

			token->str		token->type
			"echo"			|	WORD
			"42 is 42"		|	WORD		<--- Variable expansion
			"-n"			|	WORD
			"|"				|	PIPE
			"/usr/bin/grep"	|	WORD		<--- Path expansion
			"1"				|	WORD
			"<"				|	REDIR_IN
			"1.txt"			|	WORD
			""				|	EMPTY
		
		2.3	To do
				-	Parse backslashes 'echo \"'
				-	Expand variables 'ARG1=42; echo $ARG1' -> 'echo 42'
				-	Expand pathnames 'cat file.txt' -> '/usr/bin/cat file.txt'
				-	Variable assignment
					->	info env
	
	3.	Build an abstract syntax tree (AST)	-	most of code done - need more tests

		-	The previously created tokens will be parsed into an AST.

		-	The AST is a binary tree-like data structure which contains 
			the hierarchy of the commands.

		-	We will use the following grammar, which is based on real bash:

			<command line>	::= 	<job> ';' <command line>
								|	<job> ';'
									<job>

			<job>			::=		<command> '|' <job>
								|	<command>

			<command>		::=		<simple command> '<' <filename>
								|	<simple command> '>' <filename>
								|	<simple command>

			<simple command>::=		<pathname> <token list>

			<token list>	::=		<token> <token list>
								|	(EMPTY)

		-	tokens will be parsed after these grammar rules

		-	for each grammar rule there will be a function which will check
			the constellation of tokens recursively.

		-	each node in the tree will be represented by this struct:

			typedef struct s_astree
			{
				struct s_astree	*left;
				struct s_astree	*right;
				char			*str;
				int				type;
			}	t_astree;

		-	node types can have the folling values:
			
			AST_PIPE		=	1		//	<command> '|' <job>
			AST_LIST		=	2		//	<job> ';' <command line>
			AST_REDIR_IN	=	4		//	<simple command> '<' <filename>
			AST_REDIR_OUT	=	8		//	<simple command> '>' <filename>
			AST_CMD			=	16		//	<pathname> <token list>	// S_CMD means simple command
			AST_CMD_ARG		=	32		//	<token> <token list>	// CMD_ARGV means argument vector for a command
			AST_TOKEN		=	64		//	<token>

		-	Example:
			Input: echo "42 is $VAR" -n | grep "1" < 1.txt	# VAR equals 42
			Tokens (after expansion):

					token->str		token.type
					"echo"			|	WORD
					"42 is 42"		|	WORD
					"-n"			|	WORD
					"|"				|	PIPE
					"/usr/bin/grep"	|	WORD
					"1"				|	WORD
					"<"				|	REDIR_IN
					"1.txt"			|	WORD
					""				|	EMPTY

			AST:

              	    ______AST_PIPE_______
                   /		           \
                  /			            \
			   __/			             \__
	    WORD|AST_CMD,                   WORD|AST_REDIR_IN, 
		   "echo"			                "1.txt"
		 /        \                        /        \
		/          \                      /          \
	   /            \                    /            \
	NULL    WORD|AST_CMD_ARG,         NULL         WORD|AST_CMD,
		     "42 is 42"                           "/usr/bin/grep"       
		      /       \                        	      /     \
			 /         \                       	     /       \
			/	        \                      	    /         \
		  NULL    WORD|AST_CMD_ARG,         	 NULL    WORD|AST_CMD_ARG,
			  	      "-n"                     	              "1"
			          /  \							          /  \
				     /    \							         /    \
			        /      \						        /      \
                  NULL    NULL						      NULL    NULL


	
	4.	Execute AST nodes	-	only theory - code still has to be written

		-	While reading the AST we will use the following data structure
			to build the command arguments which we will later pass to execve():
		
			typedef struct s_command
			{
				int argc;
				char **argv;
				/**
				*	maybe add some more variables
				*	for storing pipe fd's
				*	and redirections
				**/
			}	t_command;

			// Example: echo "42" "21"

			t_command	*cmd;

			cmd->argc = 3;
			cmd->argv = {"echo", "42", "21"};

		-	The executor will start to read the AST from the root node.
			The root node will decide how the commands will be executed.

		Let's reconsider the example from step 3:

			AST:

              	    ______AST_PIPE_______
                   /		           \
                  /			            \
			   __/			             \__
	    WORD|AST_CMD,                   WORD|AST_REDIR_IN, 
		   "echo"			                "1.txt"
		 /        \                        /        \
		/          \                      /          \
	   /            \                    /            \
	NULL    WORD|AST_CMD_ARG,         NULL         WORD|AST_CMD,
		     "42 is 42"                           "/usr/bin/grep"       
		      /       \                        	      /     \
			 /         \                       	     /       \
			/	        \                      	    /         \
		  NULL    WORD|AST_CMD_ARG,              NULL    WORD|AST_CMD_ARG,
			  	      "-n"                     	              "1"
			          /  \							          /  \
				     /    \							         /    \
			        /      \						        /      \
                  NULL    NULL						      NULL    NULL
		
		-	PIPE is the root node so we need to call a function
			which creates a pipe with the
			simple command 'echo "42 is 42" -n' as the write end,
			and the redirection job 'grep "1" < 1.txt' as the read end.

		-	So the following steps have to be done:
			1.	Create pipe
			2.	Execute simple command 'echo "42 is 42" -n'
				->	pipe write end
			3.	Execute simple command with redirection 'grep "1" < 1.txt'
				->	pipe read end
